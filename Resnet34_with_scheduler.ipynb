{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet34_with_scheduler.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kaYmOTOJs3hU",
        "QfkGIyjgupyD",
        "a9X2-Q-5WTkM",
        "3auEtamPiFL9",
        "4TERaIqw5_lA",
        "DrAS-iagYNde",
        "qO0pqVlPYVJF",
        "ajsVbGzwzhwk",
        "g8yKy5eiZEQd",
        "UcPE6p85ZGej",
        "x9ZdCZu1Xu3f",
        "xi_5mepkmJpE",
        "gioR_yPgtGof",
        "IKQ5aLUMmQbV",
        "BTT9_PEmRTJr",
        "9LDMrBFeZcFt"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIioeTx3pgIG"
      },
      "source": [
        "#Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTOca7S_2zj",
        "outputId": "43f0802c-6479-4b62-e8c7-b0ad69e070d0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiyNkyuSmHKc",
        "outputId": "dba09cbe-a4ac-48f9-e71e-838adfb3a83a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec  1 21:01:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2gkMaBbabVB",
        "outputId": "be4441d0-3c10-43a7-873f-721213495680"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaYmOTOJs3hU"
      },
      "source": [
        "## Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ueAmNUt8st",
        "outputId": "ef276c5a-9bd9-4d18-ce84-0499cde362c3"
      },
      "source": [
        "%%writefile init.sh\n",
        "\n",
        "pip install soundfile catalyst -q\n",
        "pip install torchlibrosa -q\n",
        "\n",
        "mkdir data/ data/raw/\n",
        "\n",
        "unzip -q data/raw/audio_files.zip -d data/\n",
        "unzip -q data/raw/AdditionalUtterances.zip -d data/\n",
        "unzip -q data/raw/nlp_keywords_29Oct2020.zip -d data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing init.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKlvcZYfskqH",
        "outputId": "7b867f82-dd5d-45be-ccdc-f9fc386de901"
      },
      "source": [
        "%%writefile init.py\n",
        "\n",
        "import os, sys, gc, glob\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('-prefix', type=str, default='./data/here/', help=\"postprocess folder\")\n",
        "parser.add_argument('-data', type=str, default='data/raw/', help=\"where to fing the zipfiles\")\n",
        "\n",
        "\n",
        "def preprocessing(args):\n",
        "\tdef what(splits, ns=-3):\n",
        "\t\treturn '_'.join([ splits[ns], splits[-1][:-4] ]).lower()\n",
        "\t\n",
        "\tadditionnal = glob.glob(\"data/latest_keywords/*/*.wav\")\n",
        "\tadditionnal += glob.glob(\"data/nlp_keywords/*/*.wav\")\n",
        "\n",
        "\tos.makedirs(args.prefix, exist_ok=True)\n",
        "\n",
        "\tadd = pd.DataFrame({'fn': additionnal})\n",
        "\tadd['bname'] = add['fn'].apply(lambda x: what(x.split('/')))\n",
        "\tadd['type'] = 'add'\n",
        "\tadd['target'] = add['fn'].apply(lambda x: x.split('/')[-2])\n",
        "\tadd.to_csv(args.prefix + 'AddTrain.csv', index=False)\n",
        "\n",
        "\ttrain = pd.read_csv(args.data + 'Train.csv')\n",
        "\ttrain['bname'] = train['fn'].apply(lambda x: what(x.split('/'), -2))\n",
        "\ttrain['type'] = 'base'\n",
        "\ttrain['fn'] = 'data/' + train['fn']\n",
        "\ttrain.rename(columns = {'label': 'target'}, inplace=True)\n",
        "\ttrain.to_csv(args.prefix + 'BaseTrain.csv', index=False)\n",
        "\n",
        "\ttrain = pd.concat([train, add], axis=0)\n",
        "\ttrain.to_csv(args.prefix + 'Train.csv', index=False)\n",
        "\n",
        "\tsubs = pd.read_csv(args.data + 'SampleSubmission.csv')\n",
        "\tsubs['fn'] = 'data/' + subs['fn']\n",
        "\tsubs['bname'] = subs['fn'].apply(lambda x: what(x.split('/'), -2))\n",
        "\tcols = subs.columns.tolist()\n",
        "\tsubs = subs[[cols[0]] + [cols[-1]] + cols[1:-1]]\n",
        "\tsubs.to_csv(args.prefix + 'SampleSubmission.csv', index=False)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\targs = parser.parse_args()\n",
        "\tpreprocessing(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing init.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfkGIyjgupyD"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E3bsRoOuvkj"
      },
      "source": [
        "!chmod +x init.sh\n",
        "!./init.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuJUwcczzTZd"
      },
      "source": [
        "!python init.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9X2-Q-5WTkM"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XObdABGhfVa"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSARNegOWWZd"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import librosa\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from librosa import display as libdisplay\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1b7hm-2OtAu"
      },
      "source": [
        "import torchlibrosa\n",
        "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
        "from torchlibrosa.augmentation import SpecAugmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TCDPB0mMTnd"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRna23dmG4Uw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWnNKykv3kmz"
      },
      "source": [
        "from catalyst.contrib.nn.criterion import FocalLossMultiClass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOdN59az6Mhj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuhiKmCtchG-"
      },
      "source": [
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3auEtamPiFL9"
      },
      "source": [
        "#Envs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uxu_L7dayhc"
      },
      "source": [
        "path = 'data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x46mDO1tiGaV"
      },
      "source": [
        "seed = 1999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHzC4X5_uXv"
      },
      "source": [
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-94NUtOEqVz"
      },
      "source": [
        "os.makedirs('MODELS/', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxwzxxjYV1XQ"
      },
      "source": [
        "# #Placeholder for the training and test spectogram's images\n",
        "# #It is going to store the spec, we will shortly generate.\n",
        "# os.makedirs('Imgs/Train/', exist_ok=True)\n",
        "# os.makedirs('Imgs/Test/', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TERaIqw5_lA"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrAS-iagYNde"
      },
      "source": [
        "## Basic functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g5DLzdQlNMn"
      },
      "source": [
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8bQqkjUm6Ow"
      },
      "source": [
        "def pad_or_truncate(x, audio_length):\n",
        "  \"\"\"Pad all audio to specific length.\"\"\"\n",
        "  if len(x) <= audio_length:\n",
        "      return np.concatenate((x, np.zeros(audio_length - len(x))), axis=0)\n",
        "  return x[:audio_length]\n",
        "\n",
        "def load_hdf5(hdf5_path):\n",
        "  hf = h5py.File(hdf5_path, 'r')\n",
        "  audio_name = hf['audio_name'][:].tolist()\n",
        "  waveform = hf['waveform']\n",
        "  target = hf['target'][:].tolist()\n",
        "  return audio_name, waveform, target, hf\n",
        "\n",
        "def load_npy(npy_path):\n",
        "  return np.load(npy_path)\n",
        "\n",
        "def pack_waveforms_to_npy(npy_path, df, sr=44100, secs=3):\n",
        "  \"\"\"Pack waveform and target of several audio clips to a single hdf5 file. \n",
        "  This can speed up loading and training.\n",
        "  \"\"\"\n",
        "  def __parallel(df, w, n):\n",
        "    row = df.loc[n, ['fn', 'bname', 'label']].values\n",
        "    audio_path, audio_name, target = row\n",
        "\n",
        "    if os.path.isfile(audio_path):\n",
        "      (audio, _) = librosa.core.load(audio_path, sr=sr, mono=True)\n",
        "      audio = pad_or_truncate(audio, clip_samples)\n",
        "\n",
        "      w[n] = audio\n",
        "    else:\n",
        "      print('{} File does not exist! {}'.format(n, audio_path))\n",
        "\n",
        "  # Arguments & parameters\n",
        "  clip_samples = sr*secs\n",
        "  audios_num = len(df)\n",
        "\n",
        "  # Pack waveform to hdf5\n",
        "  total_time = time.time()\n",
        "\n",
        "  wavs = np.empty((audios_num, clip_samples), dtype=np.float32)\n",
        "  _ =  Parallel()( delayed(__parallel)(df, wavs, n) for n in tqdm(range(audios_num)) )\n",
        "\n",
        "  np.save(npy_path, wavs)\n",
        "\n",
        "  print('Write to {}'.format(npy_path))\n",
        "  print('Pack npy time: {:.3f}'.format(time.time() - total_time))\n",
        "\n",
        "  return wavs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO0pqVlPYVJF"
      },
      "source": [
        "## Blocks functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im_DfIXNMfB7"
      },
      "source": [
        "def init_layer(layer):\n",
        "  \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
        "  nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "  if hasattr(layer, 'bias'):\n",
        "    if layer.bias is not None:\n",
        "      layer.bias.data.fill_(0.)\n",
        "            \n",
        "def init_bn(bn):\n",
        "  \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
        "  bn.bias.data.fill_(0.)\n",
        "  bn.weight.data.fill_(1.)\n",
        "\n",
        "class AttBlock(nn.Module):\n",
        "  def __init__(self, in_features: int, out_features: int, activation=\"linear\", temperature=1.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.activation = activation\n",
        "    self.temperature = temperature\n",
        "    self.att = nn.Conv1d(\n",
        "        in_channels=in_features,\n",
        "        out_channels=out_features,\n",
        "        kernel_size=1,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        bias=True)\n",
        "    self.cla = nn.Conv1d(\n",
        "        in_channels=in_features,\n",
        "        out_channels=out_features,\n",
        "        kernel_size=1,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        bias=True)\n",
        "\n",
        "    self.bn_att = nn.BatchNorm1d(out_features)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    init_layer(self.att)\n",
        "    init_layer(self.cla)\n",
        "    init_bn(self.bn_att)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (n_samples, n_in, n_time)\n",
        "    norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
        "    cla = self.nonlinear_transform(self.cla(x))\n",
        "    x = torch.sum(norm_att * cla, dim=2)\n",
        "    return x, norm_att, cla\n",
        "\n",
        "  def nonlinear_transform(self, x):\n",
        "    if self.activation == 'linear':\n",
        "      return x\n",
        "    elif self.activation == 'sigmoid':\n",
        "      return torch.sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S8cgekxaqlj"
      },
      "source": [
        "def get_model(config):\n",
        "  return PANNsResnetAtt(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajsVbGzwzhwk"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWpeRz0xzhwk"
      },
      "source": [
        "class PANNsResnetAtt(nn.Module):\n",
        "  def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, \n",
        "               classes_num, arch='resnet34', fc=512, apply_aug=True, top_db=None, **args):\n",
        "    super(PANNsResnetAtt, self).__init__()\n",
        "    \n",
        "    window = 'hann'\n",
        "    center = True\n",
        "    pad_mode = 'reflect'\n",
        "    ref = 1.0\n",
        "    amin = 1e-10\n",
        "\n",
        "    self.interpolate_ratio = 32  # Downsampled ratio\n",
        "    self.apply_aug = apply_aug\n",
        "\n",
        "    # Spectrogram extractor\n",
        "    self.spectrogram_extractor = Spectrogram(\n",
        "        n_fft=window_size,\n",
        "        hop_length=hop_size,\n",
        "        win_length=window_size,\n",
        "        window=window,\n",
        "        center=center,\n",
        "        pad_mode=pad_mode,\n",
        "        freeze_parameters=True)\n",
        "\n",
        "    # Logmel feature extractor\n",
        "    self.logmel_extractor = LogmelFilterBank(\n",
        "        sr=sample_rate,\n",
        "        n_fft=window_size,\n",
        "        n_mels=mel_bins,\n",
        "        fmin=fmin,\n",
        "        fmax=fmax,\n",
        "        ref=ref,\n",
        "        amin=amin,\n",
        "        top_db=top_db,\n",
        "        freeze_parameters=True)\n",
        "\n",
        "    # Spec augmenter\n",
        "    self.spec_augmenter = SpecAugmentation(\n",
        "        time_drop_width=64,\n",
        "        time_stripes_num=2,\n",
        "        freq_drop_width=8,\n",
        "        freq_stripes_num=2)\n",
        "\n",
        "    self.bn0 = nn.BatchNorm2d(mel_bins)\n",
        "\n",
        "    att_size = 1024\n",
        "\n",
        "    self.fc1 = nn.Linear(fc, att_size, bias=True)\n",
        "    self.att_block = AttBlock(att_size, classes_num, activation='linear')\n",
        "\n",
        "\n",
        "    resnet = getattr(models, arch)(pretrained=True, progress=False)\n",
        "    self.resnet_features = nn.Sequential(\n",
        "        resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool,\n",
        "        resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
        "    )\n",
        "    # del self.resnet_features.avgpool\n",
        "    # del self.resnet_features.fc\n",
        "\n",
        "    self.init_weight()\n",
        "\n",
        "  def init_weight(self):\n",
        "    init_bn(self.bn0)\n",
        "    init_layer(self.fc1)\n",
        "      \n",
        "  def cnn_feature_extractor(self, x):\n",
        "    x = self.resnet_features(x)\n",
        "    return x\n",
        "  \n",
        "  def preprocess(self, input, mixup_lambda=None):\n",
        "    x = self.spectrogram_extractor(input)  # (batch_size, 1, time_steps, freq_bins)\n",
        "    x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
        "\n",
        "    frames_num = x.shape[2]\n",
        "\n",
        "    x = x.transpose(1, 3)\n",
        "    x = self.bn0(x)\n",
        "    x = x.transpose(1, 3)\n",
        "\n",
        "    if self.training and self.apply_aug:\n",
        "        x = self.spec_augmenter(x)\n",
        "\n",
        "    # Mixup on spectrogram\n",
        "    if self.training  and self.apply_aug and mixup_lambda is not None:\n",
        "        x = do_mixup(x, mixup_lambda)\n",
        "\n",
        "    return x, frames_num\n",
        "      \n",
        "  def forward(self, input, mixup_lambda=None):\n",
        "    \"\"\"\n",
        "    Input: (batch_size, data_length)\"\"\"\n",
        "    x, frames_num = self.preprocess(input, mixup_lambda=mixup_lambda)\n",
        "\n",
        "    if mixup_lambda is not None:\n",
        "        b = (b*c)//2\n",
        "        c = 1\n",
        "    \n",
        "    # Output shape (batch size, channels, time, frequency)\n",
        "    x = x.expand(x.shape[0], 3, x.shape[2], x.shape[3])\n",
        "    x = self.cnn_feature_extractor(x)\n",
        "    \n",
        "    # Aggregate in frequency axis\n",
        "    x = torch.mean(x, dim=3)\n",
        "\n",
        "    x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "    x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "    x = x1 + x2\n",
        "\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = x.transpose(1, 2)\n",
        "    x = F.relu_(self.fc1(x))\n",
        "    x = x.transpose(1, 2)\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "    (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
        "    # segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "\n",
        "    # # Get framewise output\n",
        "    # framewise_output = interpolate(segmentwise_output,\n",
        "    #                                 self.interpolate_ratio)\n",
        "    # framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
        "    # frame_shape =  framewise_output.shape\n",
        "    # clip_shape = clipwise_output.shape\n",
        "    # output_dict = {\n",
        "    #     'framewise_output': framewise_output.reshape(b, c, frame_shape[1],frame_shape[2]),\n",
        "    #     'clipwise_output': clipwise_output.reshape(b, c, clip_shape[1]),\n",
        "    # }\n",
        "\n",
        "    return clipwise_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8yKy5eiZEQd"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJ0lMXYnHxt"
      },
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, df, task='train', **kwargs):\n",
        "    super(AudioDataset, self).__init__()\n",
        "    self.df = df\n",
        "    self.task = task\n",
        "    self.c = len(words)\n",
        "    self.classes = words\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.loc[idx]\n",
        "    iidx, label = row[\"index\"], 0\n",
        "\n",
        "    if self.task=='train':\n",
        "      label = row.label\n",
        "      waveform = waveforms[iidx]\n",
        "    else:\n",
        "      waveform = waveforms_[iidx]\n",
        "\n",
        "    return {\n",
        "        'wav': torch.tensor( waveform, dtype=torch.float ),\n",
        "        'target': torch.tensor( label, dtype=torch.long )\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcPE6p85ZGej"
      },
      "source": [
        "## Training functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnDzEktyS6mH"
      },
      "source": [
        "def training_fn(dataloader, model, opt, criterion, scheduler=None):\n",
        "  avg_loss = 0\n",
        "  avg_acc = 0\n",
        "  size = len(dataloader)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for i, data in enumerate(dataloader):\n",
        "    x,y = data['wav'].to(device), data['target'].to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    pred = model(x)\n",
        "    loss = criterion(pred, y)\n",
        "\n",
        "    avg_loss += loss.item()\n",
        "    \n",
        "    pred = pred.detach().cpu()\n",
        "    ys = y.detach().cpu()\n",
        "\n",
        "    avg_acc += (ys == pred.argmax(1)).float().mean().item()\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "\n",
        "    print('\\r[Training][{}/{}] Loss: {:.5f} - Acc : {:.5f}'.format(\n",
        "        i+1, size, avg_loss/(i+1), avg_acc/(i+1) ), end='')\n",
        "  print()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXwjzFz2S6cL"
      },
      "source": [
        "def evaluate(dataloader, model, criterion):\n",
        "  avg_loss = 0\n",
        "  avg_acc = 0\n",
        "  size = len(dataloader)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader):\n",
        "      x,y = data['wav'].to(device), data['target'].to(device)\n",
        "\n",
        "      pred = model(x)\n",
        "      \n",
        "      avg_loss += criterion(pred, y).item()\n",
        "\n",
        "      pred = pred.detach().cpu()\n",
        "      ys = y.detach().cpu()\n",
        "\n",
        "      avg_acc += (ys == pred.argmax(1)).float().mean().item()\n",
        "\n",
        "      print('\\r[Evaluation][{}/{}] Loss: {:.5f} - Acc : {:.5f}'.format(\n",
        "          i+1, size, avg_loss/(i+1), avg_acc/(i+1) ), end='')\n",
        "    print()\n",
        "    avg_loss /= size\n",
        "    avg_acc /= size\n",
        "    \n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHUdrPnUS7CJ"
      },
      "source": [
        "def predict(df, bs=2):\n",
        "  test_ds = AudioDataset(df, task='test')\n",
        "  testloader = torch.utils.data.DataLoader(test_ds, bs, shuffle=False)\n",
        "\n",
        "  predictions_labels = []\n",
        "  predictions_proba = []\n",
        "\n",
        "  out = None\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in tqdm(testloader):\n",
        "      x = data['wav'].to(device)\n",
        "\n",
        "      for i in range(n_folds):\n",
        "        if i == 0: out = F.softmax( MODELS[i](x), 1 )\n",
        "        else: out += F.softmax( MODELS[i](x), 1 )\n",
        "\n",
        "      out /= n_folds\n",
        "      out_labels = out.argmax(1).cpu().detach().numpy()\n",
        "      out_probas = out.cpu().detach().numpy()\n",
        "\n",
        "      predictions_labels += out_labels.tolist()\n",
        "      predictions_proba += out_probas.tolist()\n",
        "\n",
        "  return predictions_labels ,predictions_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QGtjqaxTShX"
      },
      "source": [
        "def run_fold(fold, config, bs=16, eval_bs=8, lr=1e-4, path='MODELS/'):\n",
        "  with torch.cuda.device(device):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  best_logloss = np.inf\n",
        "\n",
        "  fold_train = train[train.fold != fold].reset_index(drop=False)\n",
        "  fold_val = train[train.fold == fold].reset_index(drop=False)\n",
        "\n",
        "  train_ds = AudioDataset(fold_train)\n",
        "  val_ds = AudioDataset(fold_val)\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "  validloader = torch.utils.data.DataLoader(val_ds, batch_size=eval_bs, shuffle=False)\n",
        "\n",
        "  model = get_model(config)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "  scheduler = None\n",
        "  if config[\"schedule\"]:\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        opt, max_lr=1e-3, div_factor=4, steps_per_epoch=len(trainloader), epochs=epochs\n",
        "    )\n",
        "  \n",
        "  model.to(device)\n",
        "\n",
        "  loader = tqdm(range(epochs), desc=f'Fold {fold}')\n",
        "\n",
        "  for epoch in loader:\n",
        "    print(f\"[Epoch {epoch}]\")\n",
        "\n",
        "    training_fn(trainloader, model, opt, criterion, scheduler)\n",
        "    avg_logloss = evaluate(validloader, model, criterion)\n",
        "\n",
        "    if avg_logloss < best_logloss:\n",
        "      best_logloss = avg_logloss\n",
        "      torch.save(model.state_dict(), f'{path}model_state_dict_{fold}.bin')\n",
        "\n",
        "  return best_logloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ZdCZu1Xu3f"
      },
      "source": [
        "#Loading the CSVs' files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eSYcXfG6MP6Y",
        "outputId": "5bfdadf7-9296-447a-fffb-4809f0712d1a"
      },
      "source": [
        "train = pd.read_csv(path+'here/Train.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fn</th>\n",
              "      <th>target</th>\n",
              "      <th>bname</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/audio_files/IV38R7F.wav</td>\n",
              "      <td>akawuka</td>\n",
              "      <td>audio_files_iv38r7f</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/audio_files/KM4SKWT.wav</td>\n",
              "      <td>banana</td>\n",
              "      <td>audio_files_km4skwt</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/audio_files/F5POSU9.wav</td>\n",
              "      <td>obulwadde</td>\n",
              "      <td>audio_files_f5posu9</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/audio_files/MMVDXG2.wav</td>\n",
              "      <td>nnyaanya</td>\n",
              "      <td>audio_files_mmvdxg2</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/audio_files/9TVM96F.wav</td>\n",
              "      <td>pampu</td>\n",
              "      <td>audio_files_9tvm96f</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             fn     target                bname  type\n",
              "0  data/audio_files/IV38R7F.wav    akawuka  audio_files_iv38r7f  base\n",
              "1  data/audio_files/KM4SKWT.wav     banana  audio_files_km4skwt  base\n",
              "2  data/audio_files/F5POSU9.wav  obulwadde  audio_files_f5posu9  base\n",
              "3  data/audio_files/MMVDXG2.wav   nnyaanya  audio_files_mmvdxg2  base\n",
              "4  data/audio_files/9TVM96F.wav      pampu  audio_files_9tvm96f  base"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "I5q58g6xb8Rj",
        "outputId": "efab30d5-1efc-4cef-b708-fd1ac8fb6c01"
      },
      "source": [
        "sub = pd.read_csv(path+'here/SampleSubmission.csv')\n",
        "sub.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fn</th>\n",
              "      <th>bname</th>\n",
              "      <th>maize streak virus</th>\n",
              "      <th>disease</th>\n",
              "      <th>okukkoola</th>\n",
              "      <th>muwogo</th>\n",
              "      <th>mpeke</th>\n",
              "      <th>mucungwa</th>\n",
              "      <th>greens</th>\n",
              "      <th>garden</th>\n",
              "      <th>mango</th>\n",
              "      <th>bulimi</th>\n",
              "      <th>obuwuka</th>\n",
              "      <th>ebikoola</th>\n",
              "      <th>obulimi</th>\n",
              "      <th>ebisoolisooli</th>\n",
              "      <th>kaamulali</th>\n",
              "      <th>eddagala</th>\n",
              "      <th>beans</th>\n",
              "      <th>omuyembe</th>\n",
              "      <th>leaf</th>\n",
              "      <th>kisaanyi</th>\n",
              "      <th>leaves</th>\n",
              "      <th>butterfly</th>\n",
              "      <th>okuzifuuyira</th>\n",
              "      <th>micungwa</th>\n",
              "      <th>ppaapaali</th>\n",
              "      <th>emboga</th>\n",
              "      <th>kikolo</th>\n",
              "      <th>harvest</th>\n",
              "      <th>olusuku</th>\n",
              "      <th>coffee</th>\n",
              "      <th>super grow</th>\n",
              "      <th>rice</th>\n",
              "      <th>ensujju</th>\n",
              "      <th>okulima</th>\n",
              "      <th>worm</th>\n",
              "      <th>ebbugga</th>\n",
              "      <th>onion</th>\n",
              "      <th>ensigo</th>\n",
              "      <th>...</th>\n",
              "      <th>ejjobyo</th>\n",
              "      <th>omulimi</th>\n",
              "      <th>okusimba</th>\n",
              "      <th>sweet potatoes</th>\n",
              "      <th>okufuuyira</th>\n",
              "      <th>farming instructor</th>\n",
              "      <th>nnasale beedi</th>\n",
              "      <th>passion fruit</th>\n",
              "      <th>ekitooke</th>\n",
              "      <th>ebisaanyi</th>\n",
              "      <th>ekyeya</th>\n",
              "      <th>enva endiirwa</th>\n",
              "      <th>emisiri</th>\n",
              "      <th>emiyembe</th>\n",
              "      <th>amatooke</th>\n",
              "      <th>ebiwuka</th>\n",
              "      <th>farm</th>\n",
              "      <th>ebinyebwa</th>\n",
              "      <th>amappapaali</th>\n",
              "      <th>ebimera</th>\n",
              "      <th>kassooli</th>\n",
              "      <th>harvesting</th>\n",
              "      <th>emmwanyi</th>\n",
              "      <th>akamonde</th>\n",
              "      <th>obumonde</th>\n",
              "      <th>cabbages</th>\n",
              "      <th>akasaanyi</th>\n",
              "      <th>spread</th>\n",
              "      <th>ebirime</th>\n",
              "      <th>drought</th>\n",
              "      <th>kasaanyi</th>\n",
              "      <th>suckers</th>\n",
              "      <th>insects</th>\n",
              "      <th>fertilizer</th>\n",
              "      <th>nakavundira</th>\n",
              "      <th>ekiwojjolo</th>\n",
              "      <th>akawuka</th>\n",
              "      <th>ddagala</th>\n",
              "      <th>ebiwojjolo</th>\n",
              "      <th>obutungulu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/audio_files/00118N3.wav</td>\n",
              "      <td>audio_files_00118n3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 195 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             fn                bname  ...  ebiwojjolo  obutungulu\n",
              "0  data/audio_files/00118N3.wav  audio_files_00118n3  ...           0           0\n",
              "\n",
              "[1 rows x 195 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhp3f-pqMWqb"
      },
      "source": [
        "words = sub.columns[2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHJdYHlS_DYY"
      },
      "source": [
        "label = np.linspace(0, len(words)-1, len(words), dtype=np.int16)\n",
        "mapper = dict(zip(words, label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnwMYH_O_pvk"
      },
      "source": [
        "train['label'] = train['target'].map(mapper).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "A2kk8pEyWEwj",
        "outputId": "ee50cd74-b798-43e7-d45f-3f8655800bf7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fn</th>\n",
              "      <th>target</th>\n",
              "      <th>bname</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/audio_files/IV38R7F.wav</td>\n",
              "      <td>akawuka</td>\n",
              "      <td>audio_files_iv38r7f</td>\n",
              "      <td>base</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/audio_files/KM4SKWT.wav</td>\n",
              "      <td>banana</td>\n",
              "      <td>audio_files_km4skwt</td>\n",
              "      <td>base</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/audio_files/F5POSU9.wav</td>\n",
              "      <td>obulwadde</td>\n",
              "      <td>audio_files_f5posu9</td>\n",
              "      <td>base</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/audio_files/MMVDXG2.wav</td>\n",
              "      <td>nnyaanya</td>\n",
              "      <td>audio_files_mmvdxg2</td>\n",
              "      <td>base</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/audio_files/9TVM96F.wav</td>\n",
              "      <td>pampu</td>\n",
              "      <td>audio_files_9tvm96f</td>\n",
              "      <td>base</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             fn     target                bname  type  label\n",
              "0  data/audio_files/IV38R7F.wav    akawuka  audio_files_iv38r7f  base    189\n",
              "1  data/audio_files/KM4SKWT.wav     banana  audio_files_km4skwt  base    114\n",
              "2  data/audio_files/F5POSU9.wav  obulwadde  audio_files_f5posu9  base    130\n",
              "3  data/audio_files/MMVDXG2.wav   nnyaanya  audio_files_mmvdxg2  base    136\n",
              "4  data/audio_files/9TVM96F.wav      pampu  audio_files_9tvm96f  base     83"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi_5mepkmJpE"
      },
      "source": [
        "# Save wavs as npy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKkVVi7-Crjc"
      },
      "source": [
        "num_cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4A0WzJyHfu9"
      },
      "source": [
        "sr = 44100\n",
        "sec = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwLXyNWePqnw"
      },
      "source": [
        "npy_path = f'drive/My Drive/Zindi/GIZ/train_sr={sr}_sec={sec}.npy'\n",
        "test_npy_path = f'drive/My Drive/Zindi/GIZ/test_sr={sr}_sec={sec}.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4YzjfYdg9_En"
      },
      "source": [
        "if not os.path.exists(npy_path):\n",
        "  waveforms = pack_waveforms_to_npy(npy_path, train, sr=sr, secs=sec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVP1qQOQPS2B"
      },
      "source": [
        "if not os.path.exists(test_npy_path):\n",
        "  test = sub[['fn', 'bname']]\n",
        "  test['label'] = 0\n",
        "\n",
        "  waveforms_ = pack_waveforms_to_npy(test_npy_path, test, sr=sr, secs=sec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gioR_yPgtGof"
      },
      "source": [
        "# Load wavs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7oYBXVnm1g9",
        "outputId": "83660894-e0c0-49db-a24c-26acbc17a7fc"
      },
      "source": [
        "%%time\n",
        "waveforms = load_npy(npy_path)\n",
        "waveforms_ = load_npy(test_npy_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.8 ms, sys: 2.66 s, total: 2.68 s\n",
            "Wall time: 46.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5O6I6LCYcdz",
        "outputId": "87e64d8e-fb16-4f9b-ed25-445ddaeb6ea1"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKQ5aLUMmQbV"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uggl3ojlVeEz"
      },
      "source": [
        "n_folds = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mh4eTUZI86H"
      },
      "source": [
        "def make_fold(n_folds, shuffle=True):\n",
        "\n",
        "  train['fold'] = -1\n",
        "  indexes = train[train['type']=='base'].index\n",
        "  \n",
        "  fold = StratifiedKFold(n_splits = n_folds, random_state=seed, shuffle=shuffle)\n",
        "  for i, (tr, vr) in enumerate(fold.split(indexes, train.loc[indexes, 'label'])):\n",
        "    train.loc[indexes[vr], 'fold'] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtoz-WvS_Y0"
      },
      "source": [
        "make_fold(n_folds, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVBpTXVGLfqA",
        "outputId": "f22e8847-5476-4ff8-9f56-cb5b012f0c33"
      },
      "source": [
        "train.fold.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b1VNOENO4UW"
      },
      "source": [
        "epochs = 50\n",
        "device = 'cuda:0'\n",
        "lr = 1e-4\n",
        "\n",
        "classes_num = 193\n",
        "batch_size = 16\n",
        "\n",
        "config = {\n",
        "    \"sample_rate\": sr,\n",
        "    \"window_size\": 1024,\n",
        "    \"hop_size\": 320,\n",
        "    \"mel_bins\": 64,\n",
        "    \"fmin\": 50,\n",
        "    \"fmax\": 14000,\n",
        "    \"classes_num\": classes_num,\n",
        "    'arch': 'resnet34',\n",
        "    'fc': 512,\n",
        "    \"schedule\": True,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8fUyfUtKSc1",
        "outputId": "4c3a4dfc-b50a-4695-a475-f6504addc914"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT0fGu2j1Oiz"
      },
      "source": [
        "%%time\n",
        "avg_logloss = 0\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  \n",
        "  _fold_logloss = run_fold(fold, config, bs=batch_size, eval_bs=batch_size, lr=lr)\n",
        "  avg_logloss += _fold_logloss\n",
        "\n",
        "print()\n",
        "print(\"Avg LogLoss: \", avg_logloss/n_folds)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTT9_PEmRTJr"
      },
      "source": [
        "#Loading models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbdLwC2f2ISf",
        "outputId": "af2b80a6-b082-4574-8848-df6b07b00563"
      },
      "source": [
        "%%time\n",
        "MODELS = []\n",
        "\n",
        "for i in range(n_folds):\n",
        "  MODELS.append( get_model(config) )\n",
        "  MODELS[i].load_state_dict(torch.load(f'MODELS/model_state_dict_{i}.bin'))\n",
        "  MODELS[i].to(device)\n",
        "  MODELS[i].eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.92 s, sys: 2.13 s, total: 12.1 s\n",
            "Wall time: 33.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDMrBFeZcFt"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "414a8a0814664d25aa00a88a23dc4e86"
          ]
        },
        "id": "3ctfz162b5fx",
        "outputId": "8cfcb263-0a6d-4248-a030-96bd53263908"
      },
      "source": [
        "predictions_labels, predictions_proba = predict(sub.reset_index(), bs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "414a8a0814664d25aa00a88a23dc4e86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=509.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj9LGWbBq1kg"
      },
      "source": [
        "# Making a submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzPa_Qqae3LC"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['fn'] = sub['fn'].apply(lambda x: '/'.join( x.split('/')[1:] ))\n",
        "for i, label in enumerate(words):\n",
        "  submission[label] = 0.\n",
        "for (label, i) in mapper.items():\n",
        "  submission.loc[:,label] = np.array(predictions_proba)[:,i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvGMYQKihpi1"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cFo2HSCiA_w"
      },
      "source": [
        "csv_file = 'resnet34_with_scheduler.csv'\n",
        "submission.to_csv(csv_file, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}